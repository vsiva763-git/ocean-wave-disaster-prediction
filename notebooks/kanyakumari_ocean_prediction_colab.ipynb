{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b31e16",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install httpx feedparser pandas numpy matplotlib seaborn -q\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import asyncio\n",
    "import httpx\n",
    "import feedparser\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úÖ GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f44e3",
   "metadata": {},
   "source": [
    "## 2. Kanyakumari Location Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d232f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kanyakumari coordinates\n",
    "KANYAKUMARI_LAT = 8.0883\n",
    "KANYAKUMARI_LON = 77.5385\n",
    "\n",
    "print(f\"üìç Monitoring Location: Kanyakumari, Tamil Nadu, India\")\n",
    "print(f\"   Latitude: {KANYAKUMARI_LAT}¬∞N\")\n",
    "print(f\"   Longitude: {KANYAKUMARI_LON}¬∞E\")\n",
    "print(f\"   Region: Southernmost tip of Indian Peninsula\")\n",
    "print(f\"   Seas: Arabian Sea, Bay of Bengal, Indian Ocean confluence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af256b7",
   "metadata": {},
   "source": [
    "## 3. Real-Time Data Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KanyakumariOceanMonitor:\n",
    "    \"\"\"Real-time ocean data fetcher for Kanyakumari region.\"\"\"\n",
    "    \n",
    "    def __init__(self, lat: float = KANYAKUMARI_LAT, lon: float = KANYAKUMARI_LON):\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        \n",
    "    def fetch_marine_data(self) -> Dict:\n",
    "        \"\"\"Fetch current marine/wave data from Open-Meteo.\"\"\"\n",
    "        url = \"https://marine-api.open-meteo.com/v1/marine\"\n",
    "        params = {\n",
    "            \"latitude\": self.lat,\n",
    "            \"longitude\": self.lon,\n",
    "            \"current\": \"wave_height,wave_direction,wave_period,swell_wave_height,swell_wave_direction,swell_wave_period\",\n",
    "            \"hourly\": \"wave_height,wave_direction,wave_period\",\n",
    "            \"forecast_days\": 3,\n",
    "            \"timezone\": \"Asia/Kolkata\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = httpx.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Marine data fetch error: {e}\")\n",
    "            return self._mock_marine_data()\n",
    "    \n",
    "    def fetch_weather_data(self) -> Dict:\n",
    "        \"\"\"Fetch weather data from Open-Meteo.\"\"\"\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": self.lat,\n",
    "            \"longitude\": self.lon,\n",
    "            \"current\": \"temperature_2m,relative_humidity_2m,pressure_msl,wind_speed_10m,wind_direction_10m\",\n",
    "            \"hourly\": \"temperature_2m,pressure_msl,wind_speed_10m\",\n",
    "            \"forecast_days\": 3,\n",
    "            \"timezone\": \"Asia/Kolkata\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = httpx.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Weather data fetch error: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def fetch_earthquakes(self, days: int = 7, min_magnitude: float = 4.0) -> List[Dict]:\n",
    "        \"\"\"Fetch recent earthquakes from USGS.\"\"\"\n",
    "        end_time = datetime.utcnow()\n",
    "        start_time = end_time - timedelta(days=days)\n",
    "        \n",
    "        url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "        params = {\n",
    "            \"format\": \"geojson\",\n",
    "            \"starttime\": start_time.strftime(\"%Y-%m-%d\"),\n",
    "            \"endtime\": end_time.strftime(\"%Y-%m-%d\"),\n",
    "            \"minmagnitude\": min_magnitude,\n",
    "            \"minlatitude\": -10,\n",
    "            \"maxlatitude\": 30,\n",
    "            \"minlongitude\": 60,\n",
    "            \"maxlongitude\": 100,\n",
    "            \"orderby\": \"time\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = httpx.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            earthquakes = []\n",
    "            for feature in data.get(\"features\", [])[:10]:\n",
    "                props = feature[\"properties\"]\n",
    "                coords = feature[\"geometry\"][\"coordinates\"]\n",
    "                earthquakes.append({\n",
    "                    \"magnitude\": props.get(\"mag\"),\n",
    "                    \"place\": props.get(\"place\"),\n",
    "                    \"time\": datetime.fromtimestamp(props.get(\"time\", 0) / 1000).isoformat(),\n",
    "                    \"depth_km\": coords[2] if len(coords) > 2 else None,\n",
    "                    \"latitude\": coords[1],\n",
    "                    \"longitude\": coords[0],\n",
    "                    \"tsunami_flag\": props.get(\"tsunami\", 0)\n",
    "                })\n",
    "            return earthquakes\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Earthquake data fetch error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _mock_marine_data(self) -> Dict:\n",
    "        \"\"\"Generate mock marine data for testing.\"\"\"\n",
    "        return {\n",
    "            \"current\": {\n",
    "                \"wave_height\": np.random.uniform(0.5, 2.5),\n",
    "                \"wave_direction\": np.random.uniform(0, 360),\n",
    "                \"wave_period\": np.random.uniform(4, 12),\n",
    "                \"swell_wave_height\": np.random.uniform(0.3, 1.5),\n",
    "                \"swell_wave_direction\": np.random.uniform(0, 360),\n",
    "                \"swell_wave_period\": np.random.uniform(6, 15)\n",
    "            },\n",
    "            \"hourly\": {\n",
    "                \"time\": [(datetime.now() + timedelta(hours=i)).isoformat() for i in range(72)],\n",
    "                \"wave_height\": [np.random.uniform(0.5, 2.5) for _ in range(72)]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def calculate_tsunami_risk(self, marine_data: Dict, earthquakes: List[Dict]) -> Dict:\n",
    "        \"\"\"Calculate tsunami risk score based on multiple factors.\"\"\"\n",
    "        risk_score = 0.0\n",
    "        factors = []\n",
    "        \n",
    "        # Wave height factor\n",
    "        current = marine_data.get(\"current\", {})\n",
    "        wave_height = current.get(\"wave_height\", 0)\n",
    "        if wave_height > 3.0:\n",
    "            risk_score += 0.2\n",
    "            factors.append(f\"High waves: {wave_height:.1f}m\")\n",
    "        \n",
    "        # Earthquake factor\n",
    "        for eq in earthquakes[:5]:\n",
    "            mag = eq.get(\"magnitude\", 0)\n",
    "            depth = eq.get(\"depth_km\", 100)\n",
    "            \n",
    "            if mag >= 7.0 and depth < 70:\n",
    "                risk_score += 0.4\n",
    "                factors.append(f\"Major earthquake: M{mag} at {depth}km depth\")\n",
    "            elif mag >= 6.0 and depth < 50:\n",
    "                risk_score += 0.2\n",
    "                factors.append(f\"Significant earthquake: M{mag}\")\n",
    "            \n",
    "            if eq.get(\"tsunami_flag\", 0) == 1:\n",
    "                risk_score += 0.3\n",
    "                factors.append(\"Tsunami flag from USGS\")\n",
    "        \n",
    "        # Determine risk level\n",
    "        if risk_score >= 0.6:\n",
    "            risk_level = \"HIGH\"\n",
    "        elif risk_score >= 0.3:\n",
    "            risk_level = \"MODERATE\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "        \n",
    "        return {\n",
    "            \"risk_score\": min(risk_score, 1.0),\n",
    "            \"risk_level\": risk_level,\n",
    "            \"factors\": factors if factors else [\"Normal conditions\"]\n",
    "        }\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = KanyakumariOceanMonitor()\n",
    "print(\"‚úÖ Ocean Monitor initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75195f4f",
   "metadata": {},
   "source": [
    "## 4. Fetch Real-Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42198a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all data\n",
    "print(\"üîÑ Fetching real-time data from APIs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "marine_data = monitor.fetch_marine_data()\n",
    "weather_data = monitor.fetch_weather_data()\n",
    "earthquakes = monitor.fetch_earthquakes()\n",
    "tsunami_risk = monitor.calculate_tsunami_risk(marine_data, earthquakes)\n",
    "\n",
    "# Display current conditions\n",
    "current_marine = marine_data.get(\"current\", {})\n",
    "current_weather = weather_data.get(\"current\", {})\n",
    "\n",
    "print(f\"\\nüìä CURRENT CONDITIONS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S IST')}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüåä MARINE DATA:\")\n",
    "print(f\"   Wave Height: {current_marine.get('wave_height', 'N/A')} m\")\n",
    "print(f\"   Wave Period: {current_marine.get('wave_period', 'N/A')} s\")\n",
    "print(f\"   Wave Direction: {current_marine.get('wave_direction', 'N/A')}¬∞\")\n",
    "print(f\"   Swell Height: {current_marine.get('swell_wave_height', 'N/A')} m\")\n",
    "\n",
    "print(f\"\\nüå§Ô∏è WEATHER DATA:\")\n",
    "print(f\"   Temperature: {current_weather.get('temperature_2m', 'N/A')}¬∞C\")\n",
    "print(f\"   Humidity: {current_weather.get('relative_humidity_2m', 'N/A')}%\")\n",
    "print(f\"   Pressure: {current_weather.get('pressure_msl', 'N/A')} hPa\")\n",
    "print(f\"   Wind Speed: {current_weather.get('wind_speed_10m', 'N/A')} km/h\")\n",
    "\n",
    "print(f\"\\nüî¥ TSUNAMI RISK ASSESSMENT:\")\n",
    "print(f\"   Risk Level: {tsunami_risk['risk_level']}\")\n",
    "print(f\"   Risk Score: {tsunami_risk['risk_score']:.2f}\")\n",
    "print(f\"   Factors: {', '.join(tsunami_risk['factors'])}\")\n",
    "\n",
    "print(f\"\\nüåç RECENT EARTHQUAKES ({len(earthquakes)} found):\")\n",
    "for eq in earthquakes[:3]:\n",
    "    print(f\"   M{eq['magnitude']}: {eq['place']} ({eq['time'][:10]})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b078afa",
   "metadata": {},
   "source": [
    "## 5. Visualize Wave Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wave height forecast\n",
    "hourly = marine_data.get(\"hourly\", {})\n",
    "times = hourly.get(\"time\", [])[:48]  # Next 48 hours\n",
    "wave_heights = hourly.get(\"wave_height\", [])[:48]\n",
    "\n",
    "if times and wave_heights:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('üåä Kanyakumari Ocean Conditions - 48 Hour Forecast', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Wave height over time\n",
    "    ax1 = axes[0, 0]\n",
    "    hours = range(len(wave_heights))\n",
    "    ax1.fill_between(hours, wave_heights, alpha=0.3, color='blue')\n",
    "    ax1.plot(hours, wave_heights, 'b-', linewidth=2)\n",
    "    ax1.axhline(y=2.0, color='orange', linestyle='--', label='Moderate threshold')\n",
    "    ax1.axhline(y=4.0, color='red', linestyle='--', label='High threshold')\n",
    "    ax1.set_xlabel('Hours from now')\n",
    "    ax1.set_ylabel('Wave Height (m)')\n",
    "    ax1.set_title('Wave Height Forecast')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Wave height distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(wave_heights, bins=20, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "    ax2.axvline(x=np.mean(wave_heights), color='red', linestyle='--', label=f'Mean: {np.mean(wave_heights):.2f}m')\n",
    "    ax2.set_xlabel('Wave Height (m)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Wave Height Distribution')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Current conditions gauge\n",
    "    ax3 = axes[1, 0]\n",
    "    current_wave = current_marine.get('wave_height', 1.0)\n",
    "    categories = ['Normal\\n(0-1m)', 'Moderate\\n(1-2m)', 'High\\n(2-3m)', 'Extreme\\n(3m+)']\n",
    "    colors = ['green', 'yellow', 'orange', 'red']\n",
    "    values = [1, 1, 1, 1]\n",
    "    \n",
    "    # Determine current category\n",
    "    if current_wave < 1:\n",
    "        highlight = 0\n",
    "    elif current_wave < 2:\n",
    "        highlight = 1\n",
    "    elif current_wave < 3:\n",
    "        highlight = 2\n",
    "    else:\n",
    "        highlight = 3\n",
    "    \n",
    "    bar_colors = ['lightgray'] * 4\n",
    "    bar_colors[highlight] = colors[highlight]\n",
    "    \n",
    "    ax3.bar(categories, values, color=bar_colors, edgecolor='black')\n",
    "    ax3.set_ylim(0, 1.5)\n",
    "    ax3.set_title(f'Current Status: {current_wave:.1f}m')\n",
    "    ax3.set_ylabel('Severity Level')\n",
    "    \n",
    "    # Risk assessment pie\n",
    "    ax4 = axes[1, 1]\n",
    "    risk_score = tsunami_risk['risk_score']\n",
    "    safe_score = 1 - risk_score\n",
    "    \n",
    "    risk_colors = ['green' if risk_score < 0.3 else 'orange' if risk_score < 0.6 else 'red', 'lightgray']\n",
    "    ax4.pie([risk_score, safe_score], labels=['Risk', 'Safe'], colors=risk_colors,\n",
    "            autopct='%1.1f%%', startangle=90, explode=(0.05, 0))\n",
    "    ax4.set_title(f'Tsunami Risk: {tsunami_risk[\"risk_level\"]}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No forecast data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25687b29",
   "metadata": {},
   "source": [
    "## 6. CNN-LSTM Hybrid Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(layers.Layer):\n",
    "    \"\"\"Custom attention layer for sequence modeling.\"\"\"\n",
    "    \n",
    "    def __init__(self, units: int = 64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name='attention_weight',\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name='attention_bias',\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.u = self.add_weight(\n",
    "            name='attention_context',\n",
    "            shape=(self.units, 1),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        score = tf.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        attention_weights = tf.nn.softmax(tf.tensordot(score, self.u, axes=1), axis=1)\n",
    "        context = tf.reduce_sum(inputs * attention_weights, axis=1)\n",
    "        return context\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n",
    "\n",
    "print(\"‚úÖ AttentionLayer defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddeaf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_backbone(image_shape=(64, 64, 3)):\n",
    "    \"\"\"Build CNN backbone for spatial feature extraction.\"\"\"\n",
    "    inputs = layers.Input(shape=image_shape, name=\"image_input\")\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    return Model(inputs, x, name=\"cnn_backbone\")\n",
    "\n",
    "\n",
    "def build_lstm_backbone(seq_len=24, seq_features=8):\n",
    "    \"\"\"Build LSTM backbone for temporal sequence modeling.\"\"\"\n",
    "    inputs = layers.Input(shape=(seq_len, seq_features), name=\"sequence_input\")\n",
    "    \n",
    "    x = layers.Masking(mask_value=0.0)(inputs)\n",
    "    \n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(128, return_sequences=True, dropout=0.2)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(64, return_sequences=True, dropout=0.2)\n",
    "    )(x)\n",
    "    \n",
    "    # Apply attention\n",
    "    x = AttentionLayer(units=64, name=\"attention\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    return Model(inputs, x, name=\"lstm_backbone\")\n",
    "\n",
    "\n",
    "def build_multimodal_model(\n",
    "    image_shape=(64, 64, 3),\n",
    "    seq_len=24,\n",
    "    seq_features=8,\n",
    "    num_wave_classes=4,\n",
    "    num_tsunami_classes=3\n",
    "):\n",
    "    \"\"\"Build complete multimodal CNN-LSTM hybrid model.\"\"\"\n",
    "    \n",
    "    # Build backbones\n",
    "    cnn = build_cnn_backbone(image_shape)\n",
    "    lstm = build_lstm_backbone(seq_len, seq_features)\n",
    "    \n",
    "    # Get inputs and features\n",
    "    image_input = cnn.input\n",
    "    image_features = cnn.output\n",
    "    \n",
    "    seq_input = lstm.input\n",
    "    seq_features_out = lstm.output\n",
    "    \n",
    "    # Fusion layer\n",
    "    fused = layers.Concatenate(name=\"multimodal_fusion\")([image_features, seq_features_out])\n",
    "    \n",
    "    # Shared dense layers\n",
    "    x = layers.Dense(256, activation='relu')(fused)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output heads\n",
    "    wave_output = layers.Dense(num_wave_classes, activation='softmax', name='wave_severity')(x)\n",
    "    tsunami_output = layers.Dense(num_tsunami_classes, activation='softmax', name='tsunami_risk')(x)\n",
    "    height_output = layers.Dense(1, activation='linear', name='wave_height_meters')(x)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[image_input, seq_input],\n",
    "        outputs=[wave_output, tsunami_output, height_output],\n",
    "        name=\"multimodal_cnn_lstm_hybrid\"\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Model builder functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = build_multimodal_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss={\n",
    "        'wave_severity': 'categorical_crossentropy',\n",
    "        'tsunami_risk': 'categorical_crossentropy',\n",
    "        'wave_height_meters': 'mse'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'wave_severity': 1.0,\n",
    "        'tsunami_risk': 1.5,\n",
    "        'wave_height_meters': 0.5\n",
    "    },\n",
    "    metrics={\n",
    "        'wave_severity': ['accuracy'],\n",
    "        'tsunami_risk': ['accuracy'],\n",
    "        'wave_height_meters': ['mae']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTIMODAL CNN-LSTM HYBRID MODEL FOR OCEAN WAVE & TSUNAMI PREDICTION\")\n",
    "print(\"=\"*80)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5b922",
   "metadata": {},
   "source": [
    "## 7. Generate Synthetic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644cd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=1000, seq_len=24, seq_features=8):\n",
    "    \"\"\"Generate synthetic training data for demonstration.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Image data (simulating satellite/heatmap data)\n",
    "    images = np.random.randn(n_samples, 64, 64, 3).astype(np.float32)\n",
    "    \n",
    "    # Sequence data (wave height, pressure, wind, etc.)\n",
    "    sequences = np.random.randn(n_samples, seq_len, seq_features).astype(np.float32)\n",
    "    \n",
    "    # Labels\n",
    "    wave_severity = np.random.randint(0, 4, n_samples)\n",
    "    wave_severity_onehot = tf.keras.utils.to_categorical(wave_severity, 4)\n",
    "    \n",
    "    tsunami_risk = np.random.randint(0, 3, n_samples)\n",
    "    tsunami_risk_onehot = tf.keras.utils.to_categorical(tsunami_risk, 3)\n",
    "    \n",
    "    wave_height = np.random.uniform(0.5, 5.0, n_samples).astype(np.float32)\n",
    "    \n",
    "    return {\n",
    "        'images': images,\n",
    "        'sequences': sequences,\n",
    "        'wave_severity': wave_severity_onehot,\n",
    "        'tsunami_risk': tsunami_risk_onehot,\n",
    "        'wave_height': wave_height\n",
    "    }\n",
    "\n",
    "# Generate data\n",
    "print(\"üîÑ Generating synthetic training data...\")\n",
    "data = generate_synthetic_data(n_samples=2000)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(data['images'])} samples\")\n",
    "print(f\"   Images shape: {data['images'].shape}\")\n",
    "print(f\"   Sequences shape: {data['sequences'].shape}\")\n",
    "print(f\"   Wave severity classes: {data['wave_severity'].shape}\")\n",
    "print(f\"   Tsunami risk classes: {data['tsunami_risk'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d23e7",
   "metadata": {},
   "source": [
    "## 8. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "split_idx = int(len(data['images']) * 0.8)\n",
    "\n",
    "train_images = data['images'][:split_idx]\n",
    "train_sequences = data['sequences'][:split_idx]\n",
    "train_wave_severity = data['wave_severity'][:split_idx]\n",
    "train_tsunami_risk = data['tsunami_risk'][:split_idx]\n",
    "train_wave_height = data['wave_height'][:split_idx]\n",
    "\n",
    "val_images = data['images'][split_idx:]\n",
    "val_sequences = data['sequences'][split_idx:]\n",
    "val_wave_severity = data['wave_severity'][split_idx:]\n",
    "val_tsunami_risk = data['tsunami_risk'][split_idx:]\n",
    "val_wave_height = data['wave_height'][split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(train_images)}\")\n",
    "print(f\"Validation samples: {len(val_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = model.fit(\n",
    "    [train_images, train_sequences],\n",
    "    {\n",
    "        'wave_severity': train_wave_severity,\n",
    "        'tsunami_risk': train_tsunami_risk,\n",
    "        'wave_height_meters': train_wave_height\n",
    "    },\n",
    "    validation_data=(\n",
    "        [val_images, val_sequences],\n",
    "        {\n",
    "            'wave_severity': val_wave_severity,\n",
    "            'tsunami_risk': val_tsunami_risk,\n",
    "            'wave_height_meters': val_wave_height\n",
    "        }\n",
    "    ),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27926fc0",
   "metadata": {},
   "source": [
    "## 9. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Model Training History', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Total loss\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Total Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Wave severity accuracy\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(history.history['wave_severity_accuracy'], label='Training')\n",
    "ax2.plot(history.history['val_wave_severity_accuracy'], label='Validation')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Wave Severity Classification Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Tsunami risk accuracy\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(history.history['tsunami_risk_accuracy'], label='Training')\n",
    "ax3.plot(history.history['val_tsunami_risk_accuracy'], label='Validation')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_title('Tsunami Risk Classification Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Wave height MAE\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(history.history['wave_height_meters_mae'], label='Training')\n",
    "ax4.plot(history.history['val_wave_height_meters_mae'], label='Validation')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('MAE (meters)')\n",
    "ax4.set_title('Wave Height Prediction MAE')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e886d",
   "metadata": {},
   "source": [
    "## 10. Make Predictions with Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b18c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_realtime_input(marine_data: Dict, weather_data: Dict, seq_len: int = 24):\n",
    "    \"\"\"Prepare real-time data for model input.\"\"\"\n",
    "    \n",
    "    # Create synthetic image (placeholder for satellite data)\n",
    "    image = np.random.randn(1, 64, 64, 3).astype(np.float32)\n",
    "    \n",
    "    # Create sequence from hourly data\n",
    "    hourly_marine = marine_data.get(\"hourly\", {})\n",
    "    hourly_weather = weather_data.get(\"hourly\", {})\n",
    "    \n",
    "    wave_heights = hourly_marine.get(\"wave_height\", [1.0] * seq_len)[:seq_len]\n",
    "    wave_directions = hourly_marine.get(\"wave_direction\", [180] * seq_len)[:seq_len]\n",
    "    wave_periods = hourly_marine.get(\"wave_period\", [6] * seq_len)[:seq_len]\n",
    "    \n",
    "    temperatures = hourly_weather.get(\"temperature_2m\", [28] * seq_len)[:seq_len]\n",
    "    pressures = hourly_weather.get(\"pressure_msl\", [1013] * seq_len)[:seq_len]\n",
    "    wind_speeds = hourly_weather.get(\"wind_speed_10m\", [15] * seq_len)[:seq_len]\n",
    "    \n",
    "    # Pad if needed\n",
    "    def pad_list(lst, length, default=0):\n",
    "        lst = list(lst) if lst else [default] * length\n",
    "        return lst + [default] * (length - len(lst)) if len(lst) < length else lst[:length]\n",
    "    \n",
    "    wave_heights = pad_list(wave_heights, seq_len, 1.0)\n",
    "    wave_directions = pad_list(wave_directions, seq_len, 180)\n",
    "    wave_periods = pad_list(wave_periods, seq_len, 6)\n",
    "    temperatures = pad_list(temperatures, seq_len, 28)\n",
    "    pressures = pad_list(pressures, seq_len, 1013)\n",
    "    wind_speeds = pad_list(wind_speeds, seq_len, 15)\n",
    "    \n",
    "    # Additional features\n",
    "    humidity = [70] * seq_len\n",
    "    visibility = [10] * seq_len\n",
    "    \n",
    "    # Stack into sequence\n",
    "    sequence = np.array([\n",
    "        wave_heights,\n",
    "        wave_directions,\n",
    "        wave_periods,\n",
    "        temperatures,\n",
    "        pressures,\n",
    "        wind_speeds,\n",
    "        humidity,\n",
    "        visibility\n",
    "    ]).T.astype(np.float32)\n",
    "    \n",
    "    # Normalize\n",
    "    sequence = (sequence - sequence.mean(axis=0)) / (sequence.std(axis=0) + 1e-8)\n",
    "    \n",
    "    return image, sequence.reshape(1, seq_len, 8)\n",
    "\n",
    "# Prepare input from real data\n",
    "image_input, seq_input = prepare_realtime_input(marine_data, weather_data)\n",
    "\n",
    "print(f\"Image input shape: {image_input.shape}\")\n",
    "print(f\"Sequence input shape: {seq_input.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predictions = model.predict([image_input, seq_input], verbose=0)\n",
    "\n",
    "wave_probs = predictions[0][0]\n",
    "tsunami_probs = predictions[1][0]\n",
    "wave_height_pred = predictions[2][0][0]\n",
    "\n",
    "WAVE_CLASSES = ['NORMAL', 'MODERATE', 'HIGH', 'EXTREME']\n",
    "TSUNAMI_CLASSES = ['NONE', 'LOW', 'HIGH']\n",
    "\n",
    "wave_class = WAVE_CLASSES[np.argmax(wave_probs)]\n",
    "tsunami_class = TSUNAMI_CLASSES[np.argmax(tsunami_probs)]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü§ñ AI PREDICTION FOR KANYAKUMARI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüåä WAVE SEVERITY: {wave_class}\")\n",
    "print(f\"   Probabilities:\")\n",
    "for i, cls in enumerate(WAVE_CLASSES):\n",
    "    bar = '‚ñà' * int(wave_probs[i] * 20)\n",
    "    print(f\"     {cls:10s}: {wave_probs[i]*100:5.1f}% {bar}\")\n",
    "\n",
    "print(f\"\\nüî¥ TSUNAMI RISK: {tsunami_class}\")\n",
    "print(f\"   Probabilities:\")\n",
    "for i, cls in enumerate(TSUNAMI_CLASSES):\n",
    "    bar = '‚ñà' * int(tsunami_probs[i] * 20)\n",
    "    print(f\"     {cls:10s}: {tsunami_probs[i]*100:5.1f}% {bar}\")\n",
    "\n",
    "print(f\"\\nüìè PREDICTED WAVE HEIGHT: {wave_height_pred:.2f} meters\")\n",
    "print(f\"   (Current actual: {current_marine.get('wave_height', 'N/A')} meters)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f12b2b",
   "metadata": {},
   "source": [
    "## 11. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a62def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('kanyakumari_ocean_model.keras')\n",
    "print(\"‚úÖ Model saved as 'kanyakumari_ocean_model.keras'\")\n",
    "\n",
    "# Download link for Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('kanyakumari_ocean_model.keras')\n",
    "except:\n",
    "    print(\"(Not in Colab environment - model saved locally)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1713eca",
   "metadata": {},
   "source": [
    "## üåê Section 13: Run Web API in Colab with Public URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b173b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for web server\n",
    "!pip install flask flask-cors -q\n",
    "!npm install -g localtunnel > /dev/null 2>&1\n",
    "\n",
    "print(\"‚úÖ Packages installed for web server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cffed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Flask Web Application with API\n",
    "from flask import Flask, jsonify, render_template_string\n",
    "from flask_cors import CORS\n",
    "import threading\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# HTML Template for the Dashboard\n",
    "HTML_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>üåä Kanyakumari Ocean Wave & Disaster Prediction</title>\n",
    "    <link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.9.4/dist/leaflet.css\" />\n",
    "    <script src=\"https://unpkg.com/leaflet@1.9.4/dist/leaflet.js\"></script>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "    <style>\n",
    "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
    "        body { \n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; \n",
    "            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);\n",
    "            color: #fff; \n",
    "            min-height: 100vh;\n",
    "        }\n",
    "        .header {\n",
    "            background: rgba(0,0,0,0.3);\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "            border-bottom: 2px solid #00d4ff;\n",
    "        }\n",
    "        .header h1 { color: #00d4ff; font-size: 2em; }\n",
    "        .header p { color: #aaa; margin-top: 5px; }\n",
    "        .container { \n",
    "            max-width: 1400px; \n",
    "            margin: 0 auto; \n",
    "            padding: 20px;\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n",
    "            gap: 20px;\n",
    "        }\n",
    "        .card {\n",
    "            background: rgba(255,255,255,0.1);\n",
    "            border-radius: 15px;\n",
    "            padding: 20px;\n",
    "            backdrop-filter: blur(10px);\n",
    "            border: 1px solid rgba(255,255,255,0.2);\n",
    "        }\n",
    "        .card h3 { color: #00d4ff; margin-bottom: 15px; border-bottom: 1px solid #00d4ff; padding-bottom: 10px; }\n",
    "        .stat { display: flex; justify-content: space-between; padding: 10px 0; border-bottom: 1px solid rgba(255,255,255,0.1); }\n",
    "        .stat-label { color: #aaa; }\n",
    "        .stat-value { font-weight: bold; color: #00d4ff; }\n",
    "        .alert-box { padding: 15px; border-radius: 10px; margin: 10px 0; text-align: center; font-weight: bold; }\n",
    "        .alert-low { background: linear-gradient(135deg, #00c853, #00e676); color: #000; }\n",
    "        .alert-medium { background: linear-gradient(135deg, #ffc107, #ffeb3b); color: #000; }\n",
    "        .alert-high { background: linear-gradient(135deg, #ff5722, #f44336); color: #fff; }\n",
    "        .alert-critical { background: linear-gradient(135deg, #b71c1c, #d32f2f); color: #fff; animation: pulse 1s infinite; }\n",
    "        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.7; } }\n",
    "        #map { height: 300px; border-radius: 10px; }\n",
    "        .chart-container { height: 250px; }\n",
    "        .full-width { grid-column: 1 / -1; }\n",
    "        .refresh-btn {\n",
    "            background: #00d4ff;\n",
    "            color: #000;\n",
    "            border: none;\n",
    "            padding: 10px 20px;\n",
    "            border-radius: 5px;\n",
    "            cursor: pointer;\n",
    "            font-weight: bold;\n",
    "            margin-top: 10px;\n",
    "        }\n",
    "        .refresh-btn:hover { background: #00a8cc; }\n",
    "        .loading { text-align: center; padding: 50px; color: #aaa; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üåä Kanyakumari Ocean Monitoring System</h1>\n",
    "        <p>Real-time Wave & Tsunami Prediction Dashboard | Powered by AI (CNN-LSTM)</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"container\">\n",
    "        <div class=\"card\">\n",
    "            <h3>üìç Location Map</h3>\n",
    "            <div id=\"map\"></div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"card\">\n",
    "            <h3>üåä Current Conditions</h3>\n",
    "            <div id=\"conditions\">\n",
    "                <div class=\"stat\"><span class=\"stat-label\">Wave Height</span><span class=\"stat-value\" id=\"wave-height\">Loading...</span></div>\n",
    "                <div class=\"stat\"><span class=\"stat-label\">Wave Period</span><span class=\"stat-value\" id=\"wave-period\">Loading...</span></div>\n",
    "                <div class=\"stat\"><span class=\"stat-label\">Wave Direction</span><span class=\"stat-value\" id=\"wave-direction\">Loading...</span></div>\n",
    "                <div class=\"stat\"><span class=\"stat-label\">Water Temperature</span><span class=\"stat-value\" id=\"water-temp\">Loading...</span></div>\n",
    "                <div class=\"stat\"><span class=\"stat-label\">Wind Speed</span><span class=\"stat-value\" id=\"wind-speed\">Loading...</span></div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"card\">\n",
    "            <h3>ü§ñ AI Prediction</h3>\n",
    "            <div id=\"prediction-alert\" class=\"alert-box alert-low\">Analyzing...</div>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Wave Severity</span><span class=\"stat-value\" id=\"severity\">--</span></div>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Tsunami Risk</span><span class=\"stat-value\" id=\"tsunami-risk\">--</span></div>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Confidence</span><span class=\"stat-value\" id=\"confidence\">--</span></div>\n",
    "            <button class=\"refresh-btn\" onclick=\"fetchData()\">üîÑ Refresh Data</button>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"card full-width\">\n",
    "            <h3>üìà Wave Height Forecast (24 Hours)</h3>\n",
    "            <div class=\"chart-container\">\n",
    "                <canvas id=\"waveChart\"></canvas>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"card\">\n",
    "            <h3>üå°Ô∏è Weather Conditions</h3>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Temperature</span><span class=\"stat-value\" id=\"temperature\">Loading...</span></div>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Humidity</span><span class=\"stat-value\" id=\"humidity\">Loading...</span></div>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Pressure</span><span class=\"stat-value\" id=\"pressure\">Loading...</span></div>\n",
    "            <div class=\"stat\"><span class=\"stat-label\">Visibility</span><span class=\"stat-value\" id=\"visibility\">Loading...</span></div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"card\">\n",
    "            <h3>üåç Recent Earthquakes</h3>\n",
    "            <div id=\"earthquakes\"><p class=\"loading\">Loading earthquake data...</p></div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        // Initialize Map\n",
    "        const map = L.map('map').setView([8.0883, 77.5385], 10);\n",
    "        L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\n",
    "            attribution: '¬© OpenStreetMap'\n",
    "        }).addTo(map);\n",
    "        \n",
    "        const marker = L.marker([8.0883, 77.5385]).addTo(map)\n",
    "            .bindPopup('<b>Kanyakumari</b><br>Monitoring Station').openPopup();\n",
    "        \n",
    "        let waveChart = null;\n",
    "        \n",
    "        function initChart(labels, data) {\n",
    "            const ctx = document.getElementById('waveChart').getContext('2d');\n",
    "            if (waveChart) waveChart.destroy();\n",
    "            waveChart = new Chart(ctx, {\n",
    "                type: 'line',\n",
    "                data: {\n",
    "                    labels: labels,\n",
    "                    datasets: [{\n",
    "                        label: 'Wave Height (m)',\n",
    "                        data: data,\n",
    "                        borderColor: '#00d4ff',\n",
    "                        backgroundColor: 'rgba(0, 212, 255, 0.1)',\n",
    "                        fill: true,\n",
    "                        tension: 0.4\n",
    "                    }]\n",
    "                },\n",
    "                options: {\n",
    "                    responsive: true,\n",
    "                    maintainAspectRatio: false,\n",
    "                    plugins: { legend: { labels: { color: '#fff' } } },\n",
    "                    scales: {\n",
    "                        x: { ticks: { color: '#aaa' }, grid: { color: 'rgba(255,255,255,0.1)' } },\n",
    "                        y: { ticks: { color: '#aaa' }, grid: { color: 'rgba(255,255,255,0.1)' } }\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "        }\n",
    "        \n",
    "        async function fetchData() {\n",
    "            try {\n",
    "                const response = await fetch('/api/data');\n",
    "                const data = await response.json();\n",
    "                \n",
    "                // Update marine conditions\n",
    "                const marine = data.marine.current || data.marine;\n",
    "                document.getElementById('wave-height').textContent = (marine.wave_height || 'N/A') + ' m';\n",
    "                document.getElementById('wave-period').textContent = (marine.wave_period || 'N/A') + ' s';\n",
    "                document.getElementById('wave-direction').textContent = (marine.wave_direction || 'N/A') + '¬∞';\n",
    "                \n",
    "                // Update weather\n",
    "                const weather = data.weather.current || data.weather;\n",
    "                document.getElementById('water-temp').textContent = (weather.temperature_2m || weather.temperature || 'N/A') + '¬∞C';\n",
    "                document.getElementById('wind-speed').textContent = (weather.wind_speed_10m || weather.wind_speed || 'N/A') + ' km/h';\n",
    "                document.getElementById('temperature').textContent = (weather.temperature_2m || weather.temperature || 'N/A') + '¬∞C';\n",
    "                document.getElementById('humidity').textContent = (weather.relative_humidity_2m || weather.humidity || 'N/A') + '%';\n",
    "                document.getElementById('pressure').textContent = (weather.pressure_msl || weather.pressure || 'N/A') + ' hPa';\n",
    "                document.getElementById('visibility').textContent = '10 km';\n",
    "                \n",
    "                // Update prediction\n",
    "                const pred = data.prediction;\n",
    "                document.getElementById('severity').textContent = pred.wave_severity;\n",
    "                document.getElementById('tsunami-risk').textContent = (pred.tsunami_risk * 100).toFixed(1) + '%';\n",
    "                document.getElementById('confidence').textContent = (pred.confidence * 100).toFixed(1) + '%';\n",
    "                \n",
    "                const alertBox = document.getElementById('prediction-alert');\n",
    "                alertBox.textContent = pred.alert_message;\n",
    "                alertBox.className = 'alert-box alert-' + pred.alert_level;\n",
    "                \n",
    "                // Update chart\n",
    "                initChart(data.forecast.hours, data.forecast.wave_heights);\n",
    "                \n",
    "                // Update earthquakes\n",
    "                const eqDiv = document.getElementById('earthquakes');\n",
    "                if (data.earthquakes && data.earthquakes.length > 0) {\n",
    "                    eqDiv.innerHTML = data.earthquakes.slice(0, 5).map(eq => \n",
    "                        `<div class=\"stat\"><span class=\"stat-label\">M${eq.magnitude}</span><span class=\"stat-value\">${eq.place || eq.location || 'Unknown'}</span></div>`\n",
    "                    ).join('');\n",
    "                } else {\n",
    "                    eqDiv.innerHTML = '<p>No significant earthquakes detected</p>';\n",
    "                }\n",
    "            } catch (error) {\n",
    "                console.error('Error fetching data:', error);\n",
    "                document.getElementById('prediction-alert').textContent = 'Error loading data';\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Initial fetch and auto-refresh every 30 seconds\n",
    "        fetchData();\n",
    "        setInterval(fetchData, 30000);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/api/data')\n",
    "def get_data():\n",
    "    \"\"\"Get all data for the dashboard\"\"\"\n",
    "    try:\n",
    "        # Fetch real-time data\n",
    "        marine = monitor.fetch_marine_data()\n",
    "        weather = monitor.fetch_weather_data()\n",
    "        earthquakes = monitor.fetch_earthquakes()\n",
    "        \n",
    "        # Get current values for prediction\n",
    "        current_marine = marine.get(\"current\", marine)\n",
    "        current_weather = weather.get(\"current\", weather)\n",
    "        \n",
    "        wave_height = current_marine.get('wave_height', 1.0)\n",
    "        wave_period = current_marine.get('wave_period', 6.0)\n",
    "        \n",
    "        # Generate AI prediction using the trained model\n",
    "        try:\n",
    "            # Prepare inputs for multimodal model\n",
    "            image_input, seq_input = prepare_realtime_input(marine, weather)\n",
    "            predictions = model.predict([image_input, seq_input], verbose=0)\n",
    "            \n",
    "            wave_severity_pred = int(np.argmax(predictions[0][0]))\n",
    "            tsunami_risk = float(predictions[1][0][np.argmax(predictions[1][0])])\n",
    "            wave_height_pred = float(predictions[2][0][0])\n",
    "            \n",
    "            severity_labels = ['Normal', 'Moderate', 'High', 'Extreme']\n",
    "            wave_severity = severity_labels[min(wave_severity_pred, 3)]\n",
    "            confidence = float(np.max(predictions[0][0]))\n",
    "        except Exception as e:\n",
    "            print(f\"Model prediction error: {e}\")\n",
    "            # Fallback prediction based on wave height\n",
    "            if wave_height < 1.0:\n",
    "                wave_severity = 'Normal'\n",
    "                tsunami_risk = 0.05\n",
    "            elif wave_height < 2.0:\n",
    "                wave_severity = 'Moderate'\n",
    "                tsunami_risk = 0.15\n",
    "            elif wave_height < 3.0:\n",
    "                wave_severity = 'High'\n",
    "                tsunami_risk = 0.35\n",
    "            else:\n",
    "                wave_severity = 'Extreme'\n",
    "                tsunami_risk = 0.6\n",
    "            wave_height_pred = wave_height\n",
    "            confidence = 0.75\n",
    "        \n",
    "        # Determine alert level\n",
    "        if tsunami_risk > 0.7:\n",
    "            alert_level = 'critical'\n",
    "            alert_message = '‚ö†Ô∏è TSUNAMI WARNING - Evacuate immediately!'\n",
    "        elif tsunami_risk > 0.4 or wave_severity == 'Extreme':\n",
    "            alert_level = 'high'\n",
    "            alert_message = 'üî¥ High Risk - Avoid coastal areas'\n",
    "        elif tsunami_risk > 0.2 or wave_severity == 'High':\n",
    "            alert_level = 'medium'\n",
    "            alert_message = 'üü° Moderate Risk - Exercise caution'\n",
    "        else:\n",
    "            alert_level = 'low'\n",
    "            alert_message = 'üü¢ Conditions Normal - Safe for activities'\n",
    "        \n",
    "        # Generate 24-hour forecast from API data\n",
    "        hourly = marine.get(\"hourly\", {})\n",
    "        hourly_heights = hourly.get(\"wave_height\", [])[:24]\n",
    "        if not hourly_heights:\n",
    "            hourly_heights = [round(wave_height + np.random.uniform(-0.3, 0.3), 2) for _ in range(24)]\n",
    "        \n",
    "        hours = [f'{i}:00' for i in range(24)]\n",
    "        \n",
    "        return jsonify({\n",
    "            'marine': marine,\n",
    "            'weather': weather,\n",
    "            'earthquakes': earthquakes[:5],\n",
    "            'prediction': {\n",
    "                'wave_severity': wave_severity,\n",
    "                'tsunami_risk': tsunami_risk,\n",
    "                'wave_height': wave_height_pred,\n",
    "                'confidence': confidence,\n",
    "                'alert_level': alert_level,\n",
    "                'alert_message': alert_message\n",
    "            },\n",
    "            'forecast': {\n",
    "                'hours': hours,\n",
    "                'wave_heights': hourly_heights[:24]\n",
    "            }\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "print(\"‚úÖ Flask app created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7384d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the web server with public URL\n",
    "import threading\n",
    "import subprocess\n",
    "\n",
    "# Start Flask in a background thread\n",
    "def run_flask():\n",
    "    app.run(port=5000, use_reloader=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask)\n",
    "flask_thread.daemon = True\n",
    "flask_thread.start()\n",
    "\n",
    "print(\"‚úÖ Flask server started on port 5000\")\n",
    "\n",
    "# Give Flask time to start\n",
    "time.sleep(2)\n",
    "\n",
    "# Get your public IP (needed for localtunnel password)\n",
    "import urllib.request\n",
    "my_ip = urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf-8').strip()\n",
    "print(f\"\\nüîë Your IP (use as password if prompted): {my_ip}\")\n",
    "\n",
    "# Start localtunnel\n",
    "print(\"‚è≥ Creating public URL...\")\n",
    "process = subprocess.Popen(\n",
    "    ['npx', 'localtunnel', '--port', '5000'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Read output to get URL\n",
    "for _ in range(15):\n",
    "    line = process.stdout.readline()\n",
    "    if line:\n",
    "        print(line.strip())\n",
    "        if 'loca.lt' in line or 'https://' in line:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"üåä KANYAKUMARI OCEAN MONITORING DASHBOARD\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\n‚úÖ Web server is running!\")\n",
    "            print(f\"\\nüîó Click the URL above to open the dashboard\")\n",
    "            print(f\"\\nüîë If asked for password, enter: {my_ip}\")\n",
    "            print(f\"\\n‚ö†Ô∏è  Keep this cell running to maintain the server\")\n",
    "            print(\"=\"*60)\n",
    "            break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b11e8",
   "metadata": {},
   "source": [
    "## 12. Summary & Next Steps\n",
    "\n",
    "### What We Built:\n",
    "1. **Real-time Data Fetcher** - Fetches live ocean and weather data for Kanyakumari\n",
    "2. **CNN-LSTM Hybrid Model** - Multimodal architecture with attention mechanism\n",
    "3. **Multi-task Predictions** - Wave severity, tsunami risk, and wave height\n",
    "\n",
    "### To Improve:\n",
    "- Use real satellite imagery instead of synthetic data\n",
    "- Train on historical ocean event data\n",
    "- Add more seismic features for better tsunami prediction\n",
    "- Deploy as a web service using FastAPI\n",
    "\n",
    "### APIs Used:\n",
    "- **Open-Meteo Marine API** - Wave data\n",
    "- **Open-Meteo Weather API** - Weather conditions\n",
    "- **USGS Earthquake API** - Seismic monitoring\n",
    "\n",
    "---\n",
    "**üìç Kanyakumari Ocean Wave & Tsunami Prediction System**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
