"""USGS Earthquake Catalog real-time data fetcher.

Fetches recent earthquake events that may trigger tsunamis.
API docs: https://earthquake.usgs.gov/fdsnws/event/1/
"""
from __future__ import annotations

import logging
from datetime import datetime, timedelta
from math import radians, sin, cos, asin, sqrt
from typing import Dict, List, Optional

try:
    import httpx
except ImportError:
    httpx = None

import pandas as pd

LOGGER = logging.getLogger(__name__)

USGS_EARTHQUAKE_URL = "https://earthquake.usgs.gov/fdsnws/event/1/query"


def fetch_usgs_earthquakes(
    min_magnitude: float = 5.0,
    hours_back: int = 24,
    min_latitude: Optional[float] = None,
    max_latitude: Optional[float] = None,
    min_longitude: Optional[float] = None,
    max_longitude: Optional[float] = None,
    limit: int = 100,
) -> pd.DataFrame:
    """Fetch recent earthquakes from USGS catalog.
    
    Args:
        min_magnitude: Minimum earthquake magnitude (Richter scale)
        hours_back: How many hours of history to fetch
        min_latitude: Minimum latitude for bounding box filter
        max_latitude: Maximum latitude for bounding box filter
        min_longitude: Minimum longitude for bounding box filter
        max_longitude: Maximum longitude for bounding box filter
        limit: Maximum number of events to return
    
    Returns:
        DataFrame with earthquake events including:
            - time: Event timestamp
            - latitude, longitude, depth: Location
            - magnitude: Earthquake magnitude
            - place: Description of location
            - tsunami: Whether tsunami warning was issued (1 or 0)
    """
    if httpx is None:
        raise ImportError("httpx is required. Install with: pip install httpx")
    
    # Calculate time range
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=hours_back)
    
    params = {
        "format": "geojson",
        "starttime": start_time.strftime("%Y-%m-%dT%H:%M:%S"),
        "endtime": end_time.strftime("%Y-%m-%dT%H:%M:%S"),
        "minmagnitude": min_magnitude,
        "limit": limit,
        "orderby": "time-asc",
    }
    
    # Add bounding box if specified
    if all(v is not None for v in [min_latitude, max_latitude, min_longitude, max_longitude]):
        params.update({
            "minlatitude": min_latitude,
            "maxlatitude": max_latitude,
            "minlongitude": min_longitude,
            "maxlongitude": max_longitude,
        })
    
    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(USGS_EARTHQUAKE_URL, params=params)
            response.raise_for_status()
            data = response.json()
        
        if "features" not in data or not data["features"]:
            LOGGER.info("No earthquakes found matching criteria")
            return pd.DataFrame()
        
        # Parse GeoJSON features
        events = []
        for feature in data["features"]:
            props = feature["properties"]
            coords = feature["geometry"]["coordinates"]
            
            event = {
                "time": pd.to_datetime(props.get("time"), unit="ms", utc=True),
                "latitude": coords[1],
                "longitude": coords[0],
                "depth": coords[2],  # km
                "magnitude": props.get("mag"),
                "magnitude_type": props.get("magType", ""),
                "place": props.get("place", ""),
                "tsunami": props.get("tsunami", 0),
                "type": props.get("type", "earthquake"),
                "url": props.get("url", ""),
            }
            events.append(event)
        
        df = pd.DataFrame(events)
        df.set_index("time", inplace=True)
        df.sort_index(inplace=True)
        
        LOGGER.info(f"Fetched {len(df)} earthquakes (magnitude >= {min_magnitude}) from last {hours_back} hours")
        return df
        
    except Exception as exc:
        LOGGER.error(f"Failed to fetch USGS earthquake data: {exc}")
        return pd.DataFrame()


def filter_tsunami_risk_events(
    df: pd.DataFrame,
    min_magnitude: float = 6.5,
    max_depth_km: float = 70,
) -> pd.DataFrame:
    """Filter earthquakes for those with tsunami potential.
    
    Tsunamis are typically generated by:
    - Magnitude >= 6.5 (larger quakes displace more water)
    - Shallow depth (< 70 km, usually < 50 km)
    - Submarine location (under ocean)
    
    Args:
        df: DataFrame from fetch_usgs_earthquakes
        min_magnitude: Minimum magnitude threshold
        max_depth_km: Maximum depth for tsunami generation
    
    Returns:
        Filtered DataFrame with high tsunami risk events
    """
    if df.empty:
        return df
    
    filtered = df[
        (df["magnitude"] >= min_magnitude) &
        (df["depth"] <= max_depth_km)
    ].copy()
    
    LOGGER.info(f"Found {len(filtered)} events with tsunami potential (M>={min_magnitude}, depth<={max_depth_km}km)")
    return filtered


def calculate_tsunami_arrival_estimate(
    event_lat: float,
    event_lon: float,
    target_lat: float,
    target_lon: float,
    avg_speed_kmh: float = 800,
) -> Dict[str, float]:
    """Estimate tsunami arrival time at a coastal location.
    
    This is a simplified great-circle distance calculation.
    Real tsunami modeling requires bathymetry and wave propagation models.
    
    Args:
        event_lat: Earthquake latitude
        event_lon: Earthquake longitude
        target_lat: Target coastal location latitude
        target_lon: Target coastal location longitude
        avg_speed_kmh: Average tsunami speed in deep ocean (default ~800 km/h)
    
    Returns:
        Dictionary with:
            - distance_km: Distance from epicenter
            - eta_hours: Estimated time of arrival in hours
            - eta_minutes: Estimated time of arrival in minutes
    """
    def haversine(lat1, lon1, lat2, lon2):
        """Calculate distance between two points on Earth in km."""
        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * asin(sqrt(a))
        return 6371 * c  # Earth radius in km
    
    distance = haversine(event_lat, event_lon, target_lat, target_lon)
    eta_hours = distance / avg_speed_kmh
    eta_minutes = eta_hours * 60
    
    return {
        "distance_km": round(distance, 2),
        "eta_hours": round(eta_hours, 2),
        "eta_minutes": round(eta_minutes, 1),
    }
